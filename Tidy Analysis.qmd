---
title: "Tidy Analysis"
author: "Eric Mossotti"

code-fold: true

df_print: "tibble" 

format: html
toc: true
---

```{r include= FALSE}

knitr::opts_chunk$set(message = FALSE, warning = FALSE)

```

# Project Environment Set Up

## Tidyverse Packages

*tidyverse-package {tidyverse}:*

> This package is designed to make it easy to install and load multiple 'tidyverse' packages in a single step.

```{r}

# tidyverse-package {tidyverse}
library ( tidyverse )
```

## Data Import

### Sourcing

```{r}

library(dplyr)

# "https://divvy-tripdata.s3.amazonaws.com/202004-divvy-tripdata.zip"
# "202004

# [:digit:]

# memdb_frame(..., .name = unique_table_name())

# tbl_memdb(df, name = deparse(substitute(df)))

# src_memdb()

con <- DBI::dbConnect(RSQLite::SQLite(), dbname = ":memory:")

durls <- sprintf ( 
    "https://divvy-tripdata.s3.amazonaws.com/%d-divvy-tripdata.zip",
    202301:202312 )



zipNames <- sprintf ( "%d-divvy-tripdata.zip",
                      202301:202312 )
#tempfile {base}
tempZips <- tempfile ( zipNames )

# multi_download {curl}	
multi_download ( durls, destfiles = tempZips )

fileNames <- sprintf ( "%d-divvy-tripdata.csv",
                   202301:202312)

```

```{r}
unz_read <- function ( fileNames, tempZips ) {
    
    datalist <- list()
    
    for ( i in 1:length(fileNames) ) {
        
            csvFile <- unz (tempZips[i], 
                         fileNames[i] )
            
            datalist[[i]] <- data.frame(read.csv(csvFile))
            #newdf <- read.csv ( newTempfile )
        
    }
    
    return ( datalist )
}
```

```{r}
unz_read <- function ( fileNames, tempZips ) {
    
    datalist <- list()
    
    for ( i in 1:length(fileNames) ) {
        
            csvFile <- unz ( tempZips[i], 
                             fileNames[i] )
            
            datalist[[i]] <- data.frame(read.csv(csvFile))
            #newdf <- read.csv ( newTempfile )
        
    }
    
    return ( datalist )
}
```

```{r}

oneTibble <- do.call ( rbind, 
                       unz_read ( fileNames = fileNames, 
                                  temp = temp )
                       )

memories <- memdb_frame ( data )
```

```{r}

# list.files {base}
csvFileList <- list.files ( path = "tripdata", 
                            full.names = TRUE )
```

View list.

```{r}

# view {tibble} 
print ( csvFileList )
```

### Data Mapping

```{r}

# map {purrr}, 

# With list_rbind(), map can be used to directly create a dataframe from a list of files

oneTibble <- map ( csvFileList[1:2], read_csv ) |>
    
    list_rbind  ()
```

( In R a tibble is synonymous with a data frame )

```{r}

typeof (oneTibble)
```

```{r}

is_tibble ( oneTibble )
```

```{r}
is.data.frame ( oneTibble )
```

```{r}
oneTibble[1,]
```

```{r}
length(oneTibble[[1]])
```

```{r}

# drop_na {tidyr}	
oneTibble <- drop_na ( oneTibble )
```

```{r}
tibble ( Complete_Observations = 
             length ( oneTibble [[1]] ) )
```

```{r}

# Should only need to check ride_id then datetime columns for duplicates

# Maybe only need to check ride_id column? Actually, no.

# pick {dplyr}	
distinct ( oneTibble, pick ( "ride_id" ) ) |>
    
    # count {dplyr}	
    count ( name = "Distinct Ride ID's" )
```

```{r}

length ( oneTibble [[1]] )
```

```{r}

# This is a separate table used to analyze the observations returned as not distinct (n > 1). This adds an extra column (n) so didn't want to mess with the main dataframe for this.

dupTibble <- oneTibble |>
    
    # adds a count of rows for column 'n'
    add_count ( started_at, 
                ended_at, 
                start_station_name, 
                end_station_name ) |>
    
    # so that only observations that have been duplicated 1 or more times are         shown
    filter ( n > 1 ) |>
    
    # will have to retest if I need this function
    distinct ( ) |>
    
    # because we want to see all the rows, not just one row for each obs
    ungroup ( ) |>
    
    arrange ( desc ( started_at ) )
```

```{r}

print ( dupTibble[3:4] )
```

```{r}

# verify how many rows have/are duplicates
 
# nrow {base}
nrow ( dupTibble )
```

```{r}

# issue is, we need to get rid of not all of these rows, but just the extra duplicate observations. 

# If there were 2 rows of duplicates, we would want to end up with 1 row after removing the extras.

undupdTibble <- dupTibble |>
    
    # distinct {dplyr}
    distinct ( started_at, 
               start_station_name, 
               ended_at, 
               end_station_name, 
               .keep_all = TRUE )
```

```{r}

print ( undupdTibble[3:4] )
```

```{r}

nrow ( undupdTibble )
```

```{r}

distinct ( oneTibble, pick ( "ride_id" ) ) |>
    
    # count {dplyr}	
    count ( name = "Uncorrected Distinct Observations" )
```

```{r}
distinct ( oneTibble, pick ( "started_at",
                             "start_station_name",
                             "ended_at", 
                             "end_station_name" ) ) |>
    # count {dplyr}	
    count ( name = "Corrected Distinct Observations" )
```

```{r}

oneTibble <- oneTibble |>
    
    distinct ( started_at, 
               start_station_name, 
               ended_at, 
               end_station_name, 
               .keep_all = TRUE )
```

```{r}
count ( oneTibble,
        name =
            "Total Observations: Un-duplicated Dataset" )
```

```{r}
# sorting the entire table by the start_at column
oneTibble[3] |>
    
    # arrange {dplyr}	
    arrange ( started_at ) |>
    
    head ()
```

```{r}

oneTibble <- oneTibble |>

    # arrange {dplyr}
    arrange ( started_at )
```

```{r}
print(head(oneTibble[3:4]))
```

```{r}

# Split cells
oneTibble[3] |>
    
    # separate_wider_delim {tidyr}
    separate_wider_delim ( cols = c(started_at),
                           delim = " ",
                           names = c("start_date", 
                                    "start_time"),
                           cols_remove = TRUE) |>
    head()
```

```{r}
# Split cells
oneTibble[3] |>
    
    # separate_wider_delim {tidyr}
    separate_wider_delim ( cols = c(started_at),
                           delim = " ",
                           names = c("start_date", 
                                    "start_time"),
                           cols_remove = TRUE ) |>
    head ()
```

```{r}

oneTibble[4] |>
    
    separate_wider_delim ( cols = c(ended_at),
                           delim = " ",
                           names = c("end_date", 
                                    "end_time"),
                           cols_remove = TRUE ) |>
    
    head()
```

```{r}
# Split cells
oneTibble <- oneTibble |>
    
    # separate_wider_delim {tidyr}
    separate_wider_delim ( cols = c ( started_at ),
                           delim = " ",
                           names = c ( "start_date",
                                       "start_time" ),
                           cols_remove = TRUE )
```

```{r}
tibble_row ( "How many columns?" = ncol ( oneTibble ) )
```

```{r}

oneTibble <- oneTibble |>
    
    separate_wider_delim ( cols = c(ended_at),
                           delim = " ",
                           names = c("end_date", 
                                    "end_time"),
                           cols_remove = TRUE )
```

```{r}
tibble_row ( "How many columns?" = ncol ( oneTibble ) )
```

Â 

```{r}

head ( oneTibble )
```

```{r}

oneTibble2 <- oneTibble |>
    
    group_by ( rideable_type ) |>
    
    # nest {tidyr}
    nest ()
```

```{r}
# download.file {utils}	

# https://divvy-tripdata.s3.amazonaws.com/index.html

download.file(url, 
              destfile, 
              method, 
              quiet = FALSE, 
              mode = "w",
              cacheOK = TRUE,
              extra = getOption("download.file.extra"),
              headers = NULL, ...)

# connections {base}

unz(description, 
    filename, 
    open = "", 
    encoding = getOption ( "encoding" ) )


#tempfile {base}

tempfile(pattern = "file", tmpdir = tempdir(), fileext = "")

tempdir(check = FALSE)

# unlink {base}	
## unlink deletes the file(s) or directories specified by x.

unlink(x, recursive = FALSE, force = FALSE, expand = TRUE)


html <- read_html("http://rvest.tidyverse.org/")
class(html)
#> [1] "xml_document" "xml_node"


```

```{r}
    session_jump_to ( "202301-divvy-tripdata.zip" )
```
