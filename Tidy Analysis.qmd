---
title: "Professional Data Analysis"
author: "Eric Mossotti"

code-fold: true

#df_print: "tibble" 

format: html
toc: true
---

#### Future Plans:

-   [Use Quarto Pub for project deployment](https://quarto.org/docs/publishing/quarto-pub.html)

-   

```{r include = FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)
```

# Overview

The dataset is immense with millions of observations from just a single year. It seems to be regularly updated with more data, interestingly enough, despite being simulated.

This doesn't require much domain knowledge to understand, but it is realistic (with errors) and challenging enough for data analysis.

## Importing Data Efficiently

.ZIP files are commonplace as they reduce long term storage requirements. There may already be a function that does this but it seemed a custom function was needed to unzip and relocate .CSV's to a separate folder. The .ZIP files folder deleted from the working directory after relocating files to save on overhead.

```{r}

# Lists of download / zips / file addresses. 

durls <-
    sprintf("https://divvy-tripdata.s3.amazonaws.com/%d-divvy-tripdata.zip",
            202301:202312)

tempZipPaths <- sprintf("tempZips/%d-divvy-tripdata.zip",
                     202301:202312)

fileNames <- sprintf("%d-divvy-tripdata.csv",
                      202301:202312)

tempfile_paths <- sprintf("tempFiles/%d-divvy-tripdata.csv",
                      202301:202312)

fileList <- sprintf("tripdata/%d-divvy-tripdata.csv",
                       202301:202312)

# Need some directories to store the files. 
dir.create("tempZips")

dir.create("tripdata")

dir.create("tempFiles")

# review address info that was just created
tibble::tibble("URLs" = durls,
               "Zip File Paths" = tempZipPaths,
               "File Names" = fileNames,
               "Parquet File Paths" = tempfile_paths)
```

### File Downloads

```{r}

curl::multi_download(durls,
                     destfiles = tempZipPaths)
```

### Unzip, Convert and Relocate

Converting the CSV files to Parquet saves on overhead, also. With CSV files, the data files in their original form were \~1GB; with Parquet, around 0.3GB. It seemed overkill to have a partitioned dataset filesystem for only 0.3GB of data.

[R for Data Science: Chapter 22: Arrow](https://r4ds.hadley.nz/arrow "Arrow")

```{r}

# A custom function that makes unzipping, converting and relocating files all at once, simple. 
unz_relocate <- function (x = tempfile_paths,
                          y = tempZipPaths,
                          z = fileNames) {
    for (i in seq(x)) {
        utils::unzip(y[i],
                     z[i])
        file.rename(z[i],
                    x[i])
    }
}

unz_relocate()

unlink("tempZips",
       recursive = TRUE)
```

```{r}

tripTibble <- purrr::map(tempfile_paths[1:12],
                         arrow::read_csv_arrow) |>
    purrr::list_rbind()

original_nobs <- nrow(tripTibble)

tripTibble <- tripTibble |>
    tidyr::drop_na()

complete_nobs <- nrow(tripTibble)

textvector <- c(" Count before dropping incomplete rows: ",
                "Count after dropping incomplete rows: ")

cat(textvector[1], original_nobs, 
    "\n \n",
    textvector[2], complete_nobs
    )
```

```{r}

tripTibble <- tripTibble |>
    dplyr::mutate("trip_time" =
                         lubridate::time_length(
                             lubridate::interval(started_at,
                                                 ended_at),
                             unit = "minute"),
                  .keep = "all")
```

```{r}

tripTibble |> arrow::write_dataset("tempFiles",
                                   existing_data_behavior = "delete")

fileList <- list.files(path = "tempFiles",
                              full.names = TRUE,
                              recursive = TRUE)

fileList
```

```{r}

tripset <- arrow::open_dataset(sources = fileList[1],
                               format = "parquet") |>
    dplyr::group_by(month = lubridate::month(started_at),
                    weekday = lubridate::wday(started_at),
                    hour = lubridate::hour(started_at)) |>
    dplyr::select(
        ride_id,
        rideable_type,
        started_at,
        start_station_name,
        start_station_id,
        ended_at,
        end_station_name,
        end_station_id,
        member_casual,
        trip_time,
        month,
        weekday,
        hour
    ) |>
   dplyr::ungroup()

tripset |>
    arrow::to_duckdb() |>
    dplyr::count() 

tripset |> arrow::write_dataset(path = "tripdata",
                                format = "parquet",
                                existing_data_behavior = "delete")

tripset <- arrow::open_dataset(sources = "tripdata",
                              format = "parquet")

unlink("tempFiles",
       recursive = TRUE)

# Wanted to verify where the extracted data is at. 
fileList <- list.files(path = "tripdata",
                              full.names = TRUE,
                              recursive = TRUE)

fileList
```

[Why DuckDB?](https://duckdb.org/why_duckdb)

```{r}

dbconn <- DBI::dbConnect(duckdb::duckdb())

# For querying the arrow dataset with the benefits of an OLAP database. 
duckdb::duckdb_register_arrow(dbconn,
                              "trip_data",
                              tripset)
```

```{r}

doubleDecimalTibble <- tripset |>
    dplyr::select(end_station_id) |>
    as.data.frame() |>
    dplyr::filter(stringr::str_detect(end_station_id,
                                      "\\.[1-9]$")) |>
    dplyr::arrange(end_station_id) |>
    arrow::as_arrow_array() |>
    tibble::as_tibble()

# This is a separate table used to analyze the observations returned as not distinct (n > 1). This adds an extra column labeled "n".
dupeTable <- tripset |>
    arrow::to_duckdb() |>
    dplyr::select(started_at:end_station_name) |>
    # Counts of unique rows added for column 'n'
    dplyr::add_count(started_at,
                     ended_at,
                     start_station_name,
                     end_station_name) |>
    # Only observations that have been duplicated 1 or more 
    # times are shown
    dplyr::filter(n > 1) |>
    # We want to see all rows, not just one row for each obs
    dplyr::ungroup() |>
    dplyr::arrange(started_at) |>
    arrow::to_arrow() |>
    dplyr::collect() |>
    arrow::as_arrow_array() |>
    tibble::as_tibble()
```

We started with 5,719,877 observations for the time period of Jan-Dec 2023, then removed 1,388,170 of those original observations which were incomplete.

Of the other columns, it seems that the start_time, end_time, start_station, and end_station could show if there are possibly hidden duplicated observations.

I assumed that having the exact same times/dates and stations for two different ride IDs is a mistake. Although, I do not know how that error would happen. I could have assumed one person could check out multiple cycles at once. That, however, has only happened 18 times over the course of a full year. Since it's only one copy every time, that also raises a red flag.

Maybe we only need to check the ride_id column? Initially, the assumption that 4,331,707 is what should be expected as total unique observations. Perhaps it's not that easy, though? Checking the other possible parameters:

```{r}

n <- dupeTable |> 
    dplyr::distinct(n) |>
    as.integer()

cat("All distinct values of duplicates: ", 
    n)
```

```{r}

cat("Total observations that have and are duplicates: ",
       length(dupeTable[[1]]))
```

By applying distinct() on dupeTable, we see the only distinct value is 2. We can safely conclude that, of the duplicates, each has a mininum and maximum of 1 extra copy.

Number of rows in the dupeTable is 36. Because each duplicated observation has one duplicate (n = 2), expected removed nobs is 18.

```{r}

# The issue is, we need to get rid of not all of these rows, but just the extra duplicate observations. 

# If there were 2 rows of duplicates, we would want to end up with 1 row after removing the extras.
undupedTable <- dupeTable |>
    arrow::to_duckdb() |>
    dplyr::distinct(started_at,
                     start_station_name,
                     ended_at,
                     end_station_name,
                     .keep_all = TRUE) |>
    arrow::to_arrow() |>
    dplyr::collect() |>
    arrow::as_arrow_array() |>
    tibble::as_tibble()
```

```{r}

n <- undupedTable |>
    dplyr::select(started_at) |>
    dplyr::distinct() |>
    dplyr::count() |>
    as.integer()

cat("Count of distinct observations: ", n)
```

The count of observed distinct values for the un-duplicated table was indeed 18.

```{r}

# Run a count on how many rows or observations there are in the dataset.
incorrectDistinct <- tripset |>
    arrow::to_duckdb() |>
    dplyr::distinct(dplyr::pick("ride_id")) |>
    dplyr::count(name = "Incorrect Distinct Observations") |>
    arrow::to_arrow() |>
    dplyr::collect() |>
    arrow::as_arrow_array() |>
    tibble::as_tibble() |>
    as.integer()

cat("The incorrect count of distinct observations:", incorrectDistinct)
```

```{r}

correctDistinct <- tripset |>
    arrow::to_duckdb() |>
    dplyr::distinct(
        dplyr::pick(
            "started_at",
            "start_station_name",
            "ended_at",
            "end_station_name"
        )
    ) |>
    dplyr::count() |>
    arrow::to_arrow() |>
    dplyr::collect() |>
    arrow::as_arrow_array() |>
    tibble::as_tibble() |>
    as.integer()

cat("The corrected count of distinct observations we expect to see: ", correctDistinct)
```

```{r}

tripset |>
    arrow::to_duckdb() |>
    dplyr::distinct(
        dplyr::pick(
            "started_at",
            "start_station_name",
            "ended_at",
            "end_station_name"
        )
    ) |>
    arrow::to_arrow() |>
    dplyr::collect() |>
    arrow::as_arrow_array() |>
    tibble::as_tibble() |>
    dplyr::glimpse()
```

```{r}

correctionTibble <-
    tibble::tibble(
        Incorrect= incorrectDistinct,
        Correct = correctDistinct,
        Removed = Incorrect - Correct
    )

correctionTibble
```

The incorrect number of observations (nobs) was 4,331,707. The correct nobs after removing duplicated obs was 4,331,689. In short, 18 additional obs were removed.

```{r}

tempTibb <- tripset |>
    dplyr::select(ride_id:month) |>
    arrow::to_duckdb() |>
    dplyr::distinct(started_at, 
                    start_station_name, 
                    ended_at,
                    end_station_name, 
                    .keep_all = TRUE) |>
    arrow::to_arrow() |>
    dplyr::collect() |>
    arrow::as_arrow_array() |>
    tibble::as_tibble()

# sorting the entire table by the start_at column
tempTibb <- tempTibb |>
    dplyr::arrange(started_at) |>
    arrow::as_arrow_array() |>
    tibble::as_tibble()
    
tempTibb |>
    arrow::write_dataset(
        path = "tripdata",
        format = "parquet",
        existing_data_behavior = "delete"
    )
```

The actual observation count after applying distinct() on the 4 parameters listed aligns with what was expected.

```{r}

duckdb::duckdb_unregister(dbconn,
                          "trip_data")

tripset <- arrow::open_dataset(sources = "tripdata",
                               format = "parquet")
```

```{r}

decimalTibble <- tripset |>
    dplyr::select(end_station_id) |>
    as.data.frame() |>
    dplyr::group_by(end_station_id) |>
    dplyr::filter(stringr::str_detect(end_station_id, "\\.[:digit:]$")) |>
    dplyr::count() |>
    arrow::as_arrow_array() |>
    tibble::as_tibble()

check1079 <- tripset |>
    dplyr::select(end_station_id) |>
    as.data.frame() |>
    dplyr::collect() |>
    dplyr::group_by(end_station_id) |>
    dplyr::filter(stringr::str_detect(end_station_id,
                                      "[1][0][7][9]")) |>
    dplyr::count() |>
    arrow::as_arrow_array() |>
    tibble::as_tibble()

doubleDecimalTibble <- tripset |>
    dplyr::select(end_station_id) |>
    as.data.frame() |>
    dplyr::filter(stringr::str_detect(end_station_id,
                                      "\\.[1-9]$")) |>
    dplyr::arrange(end_station_id) |>
    arrow::as_arrow_array() |>
    tibble::as_tibble()

removes_oneDecimalNum <- tripset |>
    dplyr::select(end_station_id) |>
    dplyr::collect() |>
    dplyr::filter(stringr::str_detect(end_station_id,
                                      "\\.[:digit:]$")) |>
    dplyr::mutate(
        end_station_id = stringr::str_replace(
            string = end_station_id,
            pattern = "\\.[:digit:]$",
            replacement = "")
        ) |>
    arrow::as_arrow_array() |>
    tibble::as_tibble()
```

```{r}

duckdb::duckdb_register_arrow(dbconn,
                              "trip_data",
                              tripset)
```

It doesn't really seem like the station IDs containing decimals (e.g., ####.# or ####.#.#) were typos. There were no station ids with decimal numbers other than 0 or 1 after the decimal place. There were many different station IDs with one 0 after the decimal. There was only 1 station ID with a 1 following the decimal and it was in the form of "###.1.1".

# TESTING SECTION

## SQL Queries

```{r}

sql_countRiders <- paste0(
    "SELECT COUNT(*) AS 'Distinct Riders' ",
    "FROM (",
    "SELECT DISTINCT ride_id ",
    "FROM trip_data)"
)

qres_countRiders <- duckdb::dbSendQuery(conn = dbconn,
                                        statement = sql_countRiders)

fetch_countRiders <- duckdb::dbFetch(qres_countRiders)

fetch_countRiders

duckdb::dbClearResult(qres_countRiders)
```

```{r}

# Makes formatting simpler for SQL syntax
sql_selectHead <- paste0("SELECT(*) ",
                         "FROM trip_data ",
                         "LIMIT 10")

# Query result variable
qres_selectHead <- duckdb::dbSendQuery(conn = dbconn,
                                       sql_selectHead)
# Results of query in the form of a dataframe
duckdb::dbFetch(qres_selectHead)
# To save on overall memory overhead
duckdb::dbClearResult(qres_selectHead)
```

```{r}

rCounts_types <- dplyr::tbl(dbconn, 
                            "trip_data") |>
    dplyr::group_by(rideable_type) |>
    dplyr::summarize(rideTypecount = count(), .groups = "keep")

rCounts_types
```

```{r}
#or this
sql_ridetypeCounts <- paste0(
    "SELECT rideable_type, count() AS 'rt_counts' ",
    "FROM trip_data ",
    "GROUP BY rideable_type"
)

qres_ridetypeCounts <- duckdb::dbSendQuery(conn = dbconn,
                                           statement = sql_ridetypeCounts
 )

fres_rideTypeCounts <- duckdb::dbFetch(qres_ridetypeCounts)
#duckdb::dbClearResult(qres_ridetypeCounts)

fres_rideTypeCounts
```

```{r}

fres_rideTypeCounts
dplyr::glimpse(fres_rideTypeCounts)

newPlot <- ggplot2::ggplot(data = fres_rideTypeCounts,
                           mapping = ggplot2::aes(
                               x = rideable_type,
                               y = rt_counts)) +
    ggplot2::geom_col(fill = "red")

newPlot
```

```{r}

dplyr::tbl(dbconn, 
           "trip_data") |>
    dplyr::group_by(start_station_id) |>
    dplyr::summarize(StationCount = count()) |>
    dplyr::arrange(StationCount, start_station_id)
```

```{sql, connection = dbconn, output.var = "Distinct"}

SELECT COUNT 
    (DISTINCT ride_id) AS "Distinct Obs"
FROM
    trip_data
```


```{sql, connection = dbconn, output.var = "MonthlyAVG"}

SELECT AVG(RidesPerMonth) AS "MonthlyAVG"
FROM (
  SELECT MonthNum, COUNT() AS RidesPerMonth
  FROM (
    SELECT
      trip_data.*,
      EXTRACT(MONTH FROM CAST(started_at AS TIMESTAMP)) AS MonthNum
    FROM trip_data
  )
  GROUP BY MonthNum
)
```

```{sql, connection = dbconn, output.var = "sql_counts_month_rides"}

SELECT month, COUNT(member_casual) AS Rider_count
FROM trip_data
GROUP BY month
ORDER BY month
```

# Descriptive Statistics

#### Stats: Monthly Average

```{sql, connection = dbconn, output.var = "sql_avg_month_rides"}

SELECT AVG(RidesPerMonth) AS "MonthlyAVG"
FROM (
  SELECT MonthNum, COUNT() AS RidesPerMonth
  FROM (
    SELECT
      trip_data.*,
      EXTRACT(MONTH FROM CAST(started_at AS TIMESTAMP)) AS MonthNum
    FROM trip_data
  )
  GROUP BY MonthNum
)
```

```{r}

cat(stringr::str_c(as.integer(MonthlyAVG)))
```

```{sql, connection = dbconn, output.var = "sql_counts_month_casual"}

SELECT MonthNum, COUNT(member_casual) AS Casuals
FROM (
  SELECT
    started_at,
    member_casual,
    EXTRACT(MONTH FROM CAST(started_at AS TIMESTAMP)) AS MonthNum
  FROM trip_data
  WHERE (member_casual = 'casual')
)
GROUP BY MonthNum
```


```{sql, connection = dbconn, output.var = "sql_AVG_casual"}

SELECT AVG(Casuals) AS AvgCasuals
FROM (
  SELECT MonthNum, COUNT() AS Casuals
  FROM (
    SELECT
      started_at,
      member_casual,
      EXTRACT(MONTH FROM CAST(started_at AS TIMESTAMP)) AS MonthNum
    FROM trip_data
    WHERE (member_casual = 'casual')
  )
  GROUP BY MonthNum
)
```


```{sql, connection = dbconn, output.var = "sql_counts_month_casual_e"}

SELECT MonthNum, COUNT(member_casual) AS CasualsOnElectric
FROM (
  SELECT
    started_at,
    member_casual,
    rideable_type,
    EXTRACT(MONTH FROM CAST(started_at AS TIMESTAMP)) AS MonthNum
  FROM trip_data
  WHERE (member_casual = 'casual') AND (rideable_type = 'electric_bike')
)
GROUP BY MonthNum
```

```{sql, connection = dbconn}

CREATE TABLE tbl_eMembers AS
SELECT MonthNum, COUNT(member_casual) AS MembersOnElectric
FROM (
  SELECT
    started_at,
    member_casual,
    rideable_type,
    EXTRACT(MONTH FROM CAST(started_at AS TIMESTAMP)) AS MonthNum
  FROM trip_data
  WHERE (member_casual = 'member') AND (rideable_type = 'electric_bike')
)
GROUP BY MonthNum
```

```{sql, connection = dbconn}

CREATE TABLE tbl_eCasuals AS 
SELECT MonthNum, COUNT(member_casual) AS CasualsOnElectric
FROM (
  SELECT
    started_at,
    member_casual,
    rideable_type,
    EXTRACT(MONTH FROM CAST(started_at AS TIMESTAMP)) AS MonthNum
  FROM trip_data
  WHERE (member_casual = 'casual') AND (rideable_type = 'electric_bike')
)
GROUP BY MonthNum
```

```{r}

duckdb::duckdb_list_arrow(dbconn)
    
duckdb::dbListTables(dbconn)
    
dplyr::tbl(dbconn, 
           "tbl_eCasuals") |>
        dplyr::select_all()
    
dplyr::tbl(dbconn, 
           "tbl_eMembers") |>
    dplyr::select_all()
```

```{sql, connection = dbconn}

SELECT tbl_eMembers.*, CasualsOnElectric
FROM tbl_eMembers
LEFT JOIN tbl_eCasuals
  ON (tbl_eMembers.MonthNum = tbl_eCasuals.MonthNum)
```

### One Big Table

```{r}

# Create monthly count summary tables to be joined
dplyr::tbl(dbconn,
           "trip_data") |>
    dplyr::group_by(MonthNum = lubridate::month(
        lubridate::as_datetime(started_at))) |>
    dplyr::summarize(RidesPerMonth = count()) |>
    dplyr::arrange(MonthNum) |>
    as.data.frame() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "Counts_By_Month")

dplyr::tbl(dbconn,
           "trip_data") |>
    dplyr::select(started_at,
                  member_casual) |>
    dplyr::group_by(MonthNum = lubridate::month(
        lubridate::as_datetime(started_at))) |>
    dplyr::filter(member_casual == "casual") |>
    dplyr::summarize(Casuals = count(member_casual)) |>
    as.data.frame() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "Counts_By_Month_Casuals")

dplyr::tbl(dbconn,
           "trip_data") |>
    dplyr::select(started_at, member_casual) |>
    dplyr::group_by(MonthNum = lubridate::month(
        lubridate::as_datetime(started_at))) |>
    dplyr::filter(member_casual == "member") |>
    dplyr::summarize(Annuals = count(member_casual)) |>
    as.data.frame() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "Counts_By_Month_Annuals")

dplyr::tbl(dbconn,
           "trip_data") |>
    dplyr::select(started_at,
                  member_casual,
                  rideable_type) |>
    dplyr::group_by(MonthNum = lubridate::month(
        lubridate::as_datetime(started_at))) |>
    dplyr::filter(member_casual == "casual",
                  rideable_type == "electric_bike") |>
    dplyr::summarize(Casual_eBikers = count(member_casual)) |>
    as.data.frame() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "Counts_By_Month_Casual_eBikers")

dplyr::tbl(dbconn,
           "trip_data") |>
    dplyr::select(started_at,
                  member_casual,
                  rideable_type) |>
    dplyr::group_by(MonthNum = lubridate::month(
        lubridate::as_datetime(started_at))) |>
    dplyr::filter(member_casual == "member",
                  rideable_type == "electric_bike") |>
    dplyr::summarize(Annual_eBikers = count(member_casual)) |>
    as.data.frame() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "Counts_By_Month_Annual_eBikers")

dplyr::tbl(dbconn,
           "trip_data") |>
    dplyr::select(started_at,
                  member_casual,
                  rideable_type) |>
    dplyr::group_by(MonthNum = lubridate::month(
        lubridate::as_datetime(started_at))) |>
    dplyr::filter(member_casual == "member",
                  rideable_type == "classic_bike") |>
    dplyr::summarize(Annual_classicBikers = count(member_casual)) |>
    as.data.frame() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = 
                             "Counts_By_Month_Annual_classicBikers")

dplyr::tbl(dbconn,
           "trip_data") |>
    dplyr::select(started_at,
                  member_casual,
                  rideable_type) |>
    dplyr::group_by(MonthNum = lubridate::month(
        lubridate::as_datetime(started_at))) |>
    dplyr::filter(member_casual == "casual",
                  rideable_type == "classic_bike") |>
    dplyr::summarize(casual_classicBikers = count(member_casual)) |>
    as.data.frame() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = 
                             "Counts_By_Month_Casual_classicBikers")
```

```{r}

dplyr::tbl(dbconn, 
           "Counts_By_Month") |>
    tibble::view(n = 12)

dplyr::tbl(dbconn, 
           "Counts_By_Month_Casuals") |>
    tibble::view(n = 12)

dplyr::tbl(dbconn, 
           "Counts_By_Month_Annuals") |>
    tibble::view(n = 12)

dplyr::tbl(dbconn, 
           "Counts_By_Month_Casual_eBikers") |>
    tibble::view(n = 12)

dplyr::tbl(dbconn, 
           "Counts_By_Month_Annual_eBikers") |>
    tibble::view(n = 12)

dplyr::tbl(dbconn, 
           "Counts_By_Month_Annual_classicBikers") |>
    tibble::view(n = 12)

dplyr::tbl(dbconn, 
           "Counts_By_Month_Casual_classicBikers") |>
    tibble::view(n = 12)
```

```{r}

duckdb::dbListTables(dbconn)
```

```{r}

dplyr::tbl(dbconn,
           "Counts_By_Month") |>
    dplyr::left_join(y = dplyr::tbl(dbconn,
                                    "Counts_By_Month_Casuals")) |>
    dplyr::left_join(y = dplyr::tbl(dbconn,
                                    "Counts_By_Month_Annuals")) |>
    dplyr::left_join(y = dplyr::tbl(dbconn,
                                    "Counts_By_Month_Casual_eBikers")) |>
    dplyr::left_join(y = dplyr::tbl(dbconn,
                                    "Counts_By_Month_Annual_eBikers")) |>
    dplyr::left_join(y = dplyr::tbl(dbconn,
                                    "Counts_By_Month_Casual_classicBikers"))  |>
    dplyr::left_join(y = dplyr::tbl(dbconn,
                                    "Counts_By_Month_Annual_classicBikers"))
```

# Testing Observable (JS)

